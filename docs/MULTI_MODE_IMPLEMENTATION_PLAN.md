# Polaroid Multi-Mode Architecture Plan
**Date**: 2026-01-18

---

## ðŸŽ¯ Goal

Reorganize Polaroid to support 3 deployment modes:
1. **Standalone**: PyO3 Python wheel (local, native)
2. **Distributed**: gRPC polaroid-connect (multi-node)  
3. **Portable**: WASM/serverless (client-side)

---

## ðŸ—ï¸ Current Polaroid Architecture

```
polaroid/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ lib.rs              # Main library
â”‚   â”œâ”€â”€ dataframe/          # DataFrame engine
â”‚   â”œâ”€â”€ grpc_service/       # gRPC server (distributed mode)
â”‚   â””â”€â”€ lazy/               # Lazy evaluation
â”œâ”€â”€ Cargo.toml              # Rust dependencies
â””â”€â”€ docker-compose.yml      # gRPC deployment
```

**Current Mode**: Distributed only (gRPC)

---

## ðŸ”„ New Architecture

```
polaroid/
â”œâ”€â”€ crates/
â”‚   â”œâ”€â”€ polaroid-core/      # Core DataFrame engine (shared)
â”‚   â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”‚   â”œâ”€â”€ dataframe.rs
â”‚   â”‚   â”‚   â”œâ”€â”€ lazy.rs
â”‚   â”‚   â”‚   â”œâ”€â”€ arrow_ops.rs
â”‚   â”‚   â”‚   â””â”€â”€ lib.rs
â”‚   â”‚   â””â”€â”€ Cargo.toml
â”‚   â”‚
â”‚   â”œâ”€â”€ polaroid-py/        # ðŸ†• Standalone: PyO3 bindings
â”‚   â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”‚   â”œâ”€â”€ lib.rs      # PyO3 wrapper
â”‚   â”‚   â”‚   â”œâ”€â”€ dataframe.rs
â”‚   â”‚   â”‚   â””â”€â”€ conversions.rs
â”‚   â”‚   â”œâ”€â”€ Cargo.toml      # dependencies: pyo3, polaroid-core
â”‚   â”‚   â””â”€â”€ pyproject.toml  # Python wheel config
â”‚   â”‚
â”‚   â”œâ”€â”€ polaroid-connect/   # Distributed: gRPC server
â”‚   â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”‚   â”œâ”€â”€ server.rs
â”‚   â”‚   â”‚   â”œâ”€â”€ service.rs
â”‚   â”‚   â”‚   â””â”€â”€ main.rs
â”‚   â”‚   â””â”€â”€ Cargo.toml      # dependencies: tonic, polaroid-core
â”‚   â”‚
â”‚   â””â”€â”€ polaroid-wasm/      # ðŸ†• Portable: WASM module
â”‚       â”œâ”€â”€ src/
â”‚       â”‚   â”œâ”€â”€ lib.rs      # wasm-bindgen exports
â”‚       â”‚   â””â”€â”€ ops.rs
â”‚       â””â”€â”€ Cargo.toml      # dependencies: wasm-bindgen, polaroid-core
â”‚
â”œâ”€â”€ python/                  # Python client library
â”‚   â”œâ”€â”€ polaroid/
â”‚   â”‚   â”œâ”€â”€ __init__.py     # Unified API
â”‚   â”‚   â”œâ”€â”€ standalone.py   # PyO3 import
â”‚   â”‚   â”œâ”€â”€ distributed.py  # gRPC client
â”‚   â”‚   â””â”€â”€ portable.py     # WASM/PyArrow fallback
â”‚   â””â”€â”€ setup.py
â”‚
â”œâ”€â”€ Cargo.toml              # Workspace config
â”œâ”€â”€ pyproject.toml          # Python package config
â””â”€â”€ docker-compose.yml      # Distributed deployment
```

---

## ðŸ“¦ Crate Structure

### 1. polaroid-core (Shared Library)

**Purpose**: Core DataFrame engine used by all modes

**Dependencies**:
```toml
[dependencies]
polars = "0.36"
arrow = "49.0"
serde = { version = "1.0", features = ["derive"] }
```

**Exports**:
```rust
pub struct DataFrame { ... }
pub struct LazyFrame { ... }
pub trait DataFrameOps { ... }
```

**Features**: Pure Rust, no Python/gRPC/WASM dependencies

---

### 2. polaroid-py (Standalone Mode)

**Purpose**: PyO3 bindings for pip install polaroid

**Dependencies**:
```toml
[dependencies]
polaroid-core = { path = "../polaroid-core" }
pyo3 = { version = "0.20", features = ["extension-module"] }
numpy = "0.20"

[lib]
crate-type = ["cdylib"]  # Python extension
```

**Python API**:
```python
import polaroid as pl

# Polars-compatible API
df = pl.read_parquet("data.parquet")
df = df.filter(pl.col("price") > 100)
df = df.select(["symbol", "price"])
result = df.collect()  # Execute lazy query
```

**Install**:
```bash
pip install polaroid
```

---

### 3. polaroid-connect (Distributed Mode)

**Purpose**: gRPC server for multi-node deployment

**Dependencies**:
```toml
[dependencies]
polaroid-core = { path = "../polaroid-core" }
tonic = "0.10"
prost = "0.12"
tokio = { version = "1", features = ["full"] }

[[bin]]
name = "polaroid-connect"
```

**Start Server**:
```bash
polaroid-connect --host 0.0.0.0 --port 50052
```

**Docker**:
```bash
docker-compose up polaroid-connect
```

**Python Client**:
```python
import polaroid as pl

# Connect to remote server
pl.connect("grpc://localhost:50052")

df = pl.read_parquet("s3://bucket/data.parquet")
result = df.filter(pl.col("date") > "2024-01-01").collect()
```

---

### 4. polaroid-wasm (Portable Mode)

**Purpose**: WASM module for serverless/browser

**Dependencies**:
```toml
[dependencies]
polaroid-core = { path = "../polaroid-core" }
wasm-bindgen = "0.2"
serde-wasm-bindgen = "0.6"
js-sys = "0.3"

[lib]
crate-type = ["cdylib"]  # WASM output
```

**Build**:
```bash
wasm-pack build --target web --release
```

**Usage (Browser)**:
```javascript
import init, { read_parquet, filter } from './polaroid_wasm.js';

await init();
let df = read_parquet(arrayBuffer);
let filtered = filter(df, "price > 100");
```

**Usage (Python)**:
```python
import polaroid as pl

# Automatically uses WASM backend for small data
df = pl.read_parquet("small_data.parquet")  
```

---

## ðŸ”€ Unified Python API

### python/polaroid/__init__.py

```python
"""
Polaroid - High-performance DataFrame library

Modes:
- Standalone: Native PyO3 (default if installed)
- Distributed: gRPC multi-node
- Portable: PyArrow fallback (always available)
"""

from .router import get_backend, set_backend_mode, BackendMode
from .api import (
    read_parquet,
    read_csv,
    DataFrame,
    LazyFrame,
    col,
)

__all__ = [
    'read_parquet',
    'read_csv',
    'DataFrame',
    'LazyFrame',
    'col',
    'get_backend',
    'set_backend_mode',
    'BackendMode',
]
```

### Backend Selection Logic

```python
# python/polaroid/router.py

def get_backend():
    """Auto-detect best backend."""
    
    # 1. Try PyO3 (standalone)
    try:
        import polaroid._native  # PyO3 module
        return 'standalone'
    except ImportError:
        pass
    
    # 2. Try gRPC (distributed)
    if _check_grpc_available():
        return 'distributed'
    
    # 3. Fallback to portable (PyArrow)
    return 'portable'
```

---

## ðŸ› ï¸ Implementation Steps

### Phase 1: Core Refactoring (2-3 days)

1. âœ… Create workspace structure
   ```bash
   cargo new --lib crates/polaroid-core
   cargo new --lib crates/polaroid-py
   cargo new --bin crates/polaroid-connect
   cargo new --lib crates/polaroid-wasm
   ```

2. âœ… Extract core engine to polaroid-core
   - Move DataFrame/LazyFrame to core
   - Remove gRPC-specific code
   - Keep only Arrow/Polars dependencies

3. âœ… Update Cargo.toml workspace
   ```toml
   [workspace]
   members = [
       "crates/polaroid-core",
       "crates/polaroid-py",
       "crates/polaroid-connect",
       "crates/polaroid-wasm",
   ]
   ```

### Phase 2: PyO3 Bindings (2-3 days)

1. Create PyO3 wrapper (polaroid-py)
   ```rust
   use pyo3::prelude::*;
   use polaroid_core::DataFrame as CoreDataFrame;
   
   #[pyclass]
   struct DataFrame {
       inner: CoreDataFrame,
   }
   
   #[pymethods]
   impl DataFrame {
       fn filter(&self, expr: &str) -> PyResult<Self> {
           let filtered = self.inner.filter(parse_expr(expr))?;
           Ok(DataFrame { inner: filtered })
       }
   }
   ```

2. Build Python wheel
   ```bash
   cd crates/polaroid-py
   maturin develop  # For development
   maturin build --release  # For distribution
   ```

3. Test Polars compatibility
   ```python
   import polaroid as pl
   
   # Should work like Polars
   df = pl.read_parquet("data.parquet")
   result = df.filter(pl.col("price") > 100).collect()
   ```

### Phase 3: gRPC Refactoring (1-2 days)

1. Move gRPC server to polaroid-connect
   - Use polaroid-core for engine
   - Keep only gRPC service code

2. Update proto definitions
   ```protobuf
   service PolaroidConnect {
       rpc ReadParquet(ReadRequest) returns (DataFrame);
       rpc Filter(FilterRequest) returns (DataFrame);
       rpc Collect(CollectRequest) returns (ArrowBatch);
   }
   ```

3. Test distributed mode
   ```bash
   # Start server
   cargo run --bin polaroid-connect
   
   # Test from Python
   python -c "import polaroid; pl.connect('grpc://localhost:50052')"
   ```

### Phase 4: WASM Module (2-3 days)

1. Create WASM bindings (polaroid-wasm)
   ```rust
   use wasm_bindgen::prelude::*;
   use polaroid_core::DataFrame;
   
   #[wasm_bindgen]
   pub fn read_parquet(bytes: &[u8]) -> JsValue {
       let df = DataFrame::from_parquet_bytes(bytes).unwrap();
       serde_wasm_bindgen::to_value(&df).unwrap()
   }
   ```

2. Build WASM module
   ```bash
   cd crates/polaroid-wasm
   wasm-pack build --target web --release
   ```

3. Test in browser
   ```javascript
   const df = await polaroid.read_parquet(buffer);
   console.log(df.shape());
   ```

### Phase 5: Python API Unification (2 days)

1. Create unified API (python/polaroid/)
   - Auto-detect backend
   - Consistent API across all modes
   - Smart fallback logic

2. Test all modes
   ```python
   # Test standalone
   os.environ['POLAROID_MODE'] = 'standalone'
   df = pl.read_parquet("data.parquet")
   
   # Test distributed
   os.environ['POLAROID_MODE'] = 'distributed'
   df = pl.read_parquet("data.parquet")
   
   # Test portable
   os.environ['POLAROID_MODE'] = 'portable'
   df = pl.read_parquet("data.parquet")
   ```

---

## ðŸ“Š Deployment Guide

### Standalone Mode (Development)

```bash
# Install wheel
pip install polaroid

# Use locally
python -c "import polaroid as pl; df = pl.read_parquet('data.parquet')"
```

### Distributed Mode (Production)

```bash
# Start server
docker-compose up polaroid-connect

# Connect from client
export POLAROID_MODE=distributed
python app.py
```

### Portable Mode (Serverless)

```bash
# No server needed
export POLAROID_MODE=portable
python app.py  # Uses PyArrow
```

---

## ðŸŽ¯ Success Criteria

- âœ… Single codebase, 3 deployment modes
- âœ… Polars API compatibility (standalone mode)
- âœ… Existing gRPC functionality preserved
- âœ… WASM module <200KB
- âœ… Zero breaking changes to current users
- âœ… Automatic backend selection
- âœ… pip install polaroid (standalone)
- âœ… docker-compose up (distributed)
- âœ… Browser/serverless support (portable)

---

**Timeline**: 2-3 weeks  
**Effort**: High (major refactoring)  
**Impact**: Massive (enables all 3 use cases)  
**Risk**: Medium (careful testing needed)

---

**Next Action**: Start Phase 1 (core refactoring) âœ…
